# ch 8. 오차 역전파
# 오차 역전파 (back-propagation)
# 통계 강의를 생각해보면 역전파가 진짜 필요한 이유는 층이 깊어질 때 input의 영향을 확인하기 어렵기 때문이다. 기존의 순전파는 층이 깊어지면 input에서 아무리 값을 dramatic하게 바꿔도 output의 변화를 확인하기 어려웠다. 이는 input에 전혀 상관없는 output이 만들어지기에 output의 변화를 확실히 하고자 output으로부터 가중치를 계산하게 되었다.

# 임의의 값에서부터 loss가 더 이상 작아지지 않을 때까지 조금씩 움직여 가중치를 update하는 방식
# 이를 가중치의 값 변화를 기준으로 보면, 더 이상 가중치 값의 변화가 없을 때까지 loss에 대한 가중치 기울기를 빼는 것이다.

# 환경 변수 지정 (before model fit)
# 신경망 실행
# loss 계산
# 역전파 실행 = 각 가중치에 대한 loss 기울기 계산
# 결과 출력
