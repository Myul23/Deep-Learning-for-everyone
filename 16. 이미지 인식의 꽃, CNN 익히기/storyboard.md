이어서 16장 이미지 인식의 꽃, CNN 익히기입니다.

해당 장은 손글씨 이미지 데이터를 이용합니다. / 
이전과 마찬가지로 데이터를 확인하고 모델을 구상한 다음, 학습을 진행합니다.

이번에 이용할 데이터는 MNIST라는 숫자 손글씨 데이터입니다. / 
하나의 샘플이 흑백의 28 x 28의 형태를 띄고 있고, 이걸 완전 연결 계층으로 이요하고자 flatten 함수로 변환된 것을 input으로 이용할 것입니다.

얘기했던 것처럼 input은 28 x 28의 이미지를 한 줄로 폈을 때의 크기 값이고, / 모형은 전체적으로 2개의 Affine 계층으로 구성할 겁니다. / 
활성화 함수로 ReLU를, 출력층에선 SoftMax를 통해 output을 0과 9 사이의 class에 대한 확률로 나타낼 것입니다.

loss는 출력이 class니까 Cross Entropy를 통해 계산하고, 이전처럼 Adam을 통해 최적화를 진행하고자 합니다.

여기서 Early Stopping 기법을 이용해 최적화가 제대로 진행되지 않는다고 판단되면 학습을 그만두도록 하겠습니다.

계층 구성을 위해 Sequential, Dense, EarlyStopping 등과 seed를 고정하는 작업을 진행합니다.

이후, load_data 함수를 통해 6 대 1로 분리된 훈련 데이터와 test 데이터를 불러옵니다. / 
이 데이터의 입력은ㄴ 앞서처럼 하나의 샘플을 하나의 리스트로 구성시키고, keras 학습의 효율을 생각해 실수형으로 바꿔줍니다. / 
출력 데이터는 to_categorical를 통해 원-핫 인코딩을 진행합니다. / 
Dense 계층의 activation function은 ReLU와 softmax로 loss를 Cross Entropy를 통해 계산하고, adam으로 최적화를 진행합니다.

해당 모델이 학습을 진행할 때 더 나은 가중치를 찾는다면 / 다시 말해 더 적은 validation loss를 발견했다면 저장하는 식으로 checkpoint를 구성하고 / 200개씩 전체적으로 30번 학습을 진행합니다.

이를 실행시키면, 에폭이 13일 때의 값 이후로 더 나은 값을 찾지 못했으므로 에폭 23을 끝으로 학습이 종료됩니다. / 
이를 그래프로 확인하면 인덱스 12에서 validation error가 최소를 갖고 그 후론 그보다 높은 값을 가짐을 알 수 있습니다. (94%)

지금까지의 방식은 완전 연결 계층을 이용하기 위해 이미지 데이터를 한 줄로 펼쳐 사용했습니다.

그러나 지금부터는 CNN 기법을 통해 이미지를 펼치지 않고, 이미지 자체의 형태를 유지하면서 학습을 진행할 겁니다.


얘도 인덱스 12에서 최소를 찍고 23을 끝으로 더 학습을 진행하지 않았음.(97.28%)
